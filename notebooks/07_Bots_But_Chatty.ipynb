{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Bots ###\n",
    "\n",
    "<img src=https://github.com/computationaljournalism/columbia2019/raw/master/images/bots-1.jpg width=500>\n",
    "\n",
    "Today we are going to dig deeper into bots and start to look at them not simply as responding to events in the world (retweeting, say), but as \"conversational interfaces\" to information and services - voice. To get there, we need tools to help us interpret what people are saying to our bot and how we are going to respond. As we mentioned last time, bots have a wide range of interpretations - from information distribution to prototyping forms of social action.\n",
    "\n",
    "Conversationl bots are catching on in Journalism. The NYT had a significant project last year with Alexa, Quartz [has a new Bot Studio](https://bots.qz.com/), and the platforms are making tools for creating bots easier and easier. Now, the heavy lifting of turning speech to text and text to speech is a commodity API call to [Amazon's Voice Service](https://developer.amazon.com/alexa-voice-service) -- meaning voice interfaces are ridiculously simple to implement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('oTaFX3ZQlnA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, the barrier to entry for authoring a conversational bot, be it through Twitter or Alexa, is now almost entirely editorial -- what logic should we follow in architecting how a bot interacts with a human?\n",
    "\n",
    ">[From *Voice User Interface Design: New Solutions to Old Problems*](https://medium.com/microsoft-design/voice-user-interface-design-new-solutions-to-old-problems-baa36a64b3e4)<br><br>\n",
    "Like many technologies that seem fresh off the presses, conversational interfaces have been in the public consciousness for decades and in research circles even longer. Bell Laboratories debuted their “Audrey” system (the first voice controlled UI) in 1952\n",
    "<br><br>\n",
    "\n",
    "<img src=https://cdn-images-1.medium.com/max/1600/1*_7DuZTz-nVAkLnuHHcZY5A.jpeg style=\"width: 60%; border: #000000 1px outset;\"/>\n",
    "\n",
    "    Developed in 1952, Audrey -- a conversational interface, a voice interface -- even predates Star Trek’s aspirational voice controlled computer! Here's the uncaanny episode from 1966."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('1ZXugicgn6U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since that point, there have been several \"milestones\" in conversational interfaces. [This summary](https://www.altexsoft.com/blog/business/a-comprehensive-guide-to-chatbots-best-practices-for-building-conversational-interfaces/) offers a timeline that actually starts with ELIZA, whom we met last week.\n",
    "\n",
    "<br><br>\n",
    "<img src=https://www.altexsoft.com/media/2017/05/History-of-chatbots-1024x447.jpg style=\"width: 70%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "\n",
    "Befire jumping ahead 65 years or so from \"Audrey\" and \"Eliza,\" you could reasonably be wondering why it seems that so many digital conversationalists are female. I'd point you to an article in the Atlantic [\"Why Do So Many Digital Assistants Have Feminine Names?\"](https://www.theatlantic.com/technology/archive/2016/03/why-do-so-many-digital-assistants-have-feminine-names/475884/) which sites everything from academic studies that we take orders or attend to warning messages when they are delivered with a female voice, to outright sexism. I've seen a couple articles suggest that instaed [\"Genderless bots are the wave of the future\"](http://www.thedrum.com/news/2017/04/28/genderless-bots-are-the-wave-the-future). These two articles are by no means meant to be representative of the writing on this. It is just hard not to see \"Audrey\" and \"ELIZA\" and \"Alexa\" and wonder.\n",
    "\n",
    "**Everything old is new again.** \n",
    "\n",
    "*The following introduction was written by Suman DebRoy. A similar accounting of the rise of voice interfaces [can be found here at moz.com](https://moz.com/blog/voice-strategy-guide)*\n",
    "A new paradigm is ushered in because there were inefficiencies in the previous paradigm, either present in the design or caused by evolutionary usage. Lets start with that 1980s supercomputer in your pocket- the smartphone. Think about the apps on your phone. You can launch every app independenlty. But there are also digital assistants trying to become a central intelligence in your phone, through which you communicate with some of the apps. Apple, Amazon, Facebook, Google, and Microsoft’s  all provide a single interface to control specific app capabilities. However, none of them allow us to do anything drastically advanced other than reducing the number of taps we make on a phone.\n",
    "\n",
    "What exactly is better than... *theres an app for that* ? The way humans perceive personal assistants is changing, as the word \"personal\" starts to take precedence over the assistant role. It may be only a matter of time until conversational agents invade consumer markets. There is [growing anticipation](http://observer.com/2016/01/2016-will-be-the-year-of-conversational-commerce/) because stats around user interactions with chat bots vs. app usage is incredible. \n",
    "\n",
    "Both the AppStore and Google Play [host over 2 M apps each](https://www.statista.com/statistics/276623/number-of-apps-available-in-leading-app-stores/). Yet *on average, the number of apps downloaded by a person in the US every month is zero*. It seems like another paradigm shift is happening - the onset of messaging. Here are four main indicators that messaging is making apps irrelevant: \n",
    "\n",
    "1. App download slows considerably: \n",
    "    - Apps aren’t dying. But the entire space is collapsing, just like so many other industries before it. Its too crowded now, too hard to break in, numerous forced taps just for on-boarding and countless separate interfaces to keep track. Apps come with their own friction components — walled gardens, sign-up drags, untimely push notifications and re-installs. Both app makers and app users are getting increasingly frustrated with the ecosystem.\n",
    "    - App transition is costly. As a panacea, bots within WeChat enable its 600m monthly users to book taxis, or check in for flights, or buy cinema tickets, or manage banking and reserve doctors’ appointments without ever leaving the app. \n",
    "2. User Retention is poor: \n",
    "    - It is incredibly hard to make an app and keep people interested or engaged. On average, the Daily Average Users of an app drops to 77% within the first 3 days, and by a stunning 95% in first 3 months. \n",
    "3. Artificial Intelligence is improving: \n",
    "    - There are many things happening in the AI space, in the subfields of computer vision, natural language processing, algorithmic art, speech recognition etc. The field most applicable to bots is natural language understanding. \n",
    "    - Current state of bot intelligence is somewhat of an ugly marriage of bits of AI which kind of works and lots of hand coding ([but this can change soon, yes scientists are on it](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/)). To be honest, the bot world AI is still waiting for a  Pokémon Go moment with a giant breakout hit, but [we are getting there (in a fun way)](https://www.theguardian.com/technology/2016/jun/28/chatbot-ai-lawyer-donotpay-parking-tickets-london-new-york?CMP=share_btn_tw)\n",
    "4. Messaging usage is outgrowing app usage:\n",
    "    - The big 4 messsaging platforms now have more users than the big 4 social networks! Can you name them ?\n",
    "    - [\"In 2018 alone, the four largest mobile messaging apps (WhatsApp, Facebook Messenger, WeChat, Viber) held 4.1 billion combined users, surpassing 3.4 billion users on the four largest social networks (Facebook, Twitter, Instagram, LinkedIn).\"](https://www.adweek.com/digital/heres-how-messaging-is-positioned-to-dominate-in-2019/) \n",
    "    \n",
    "**Bot design**\n",
    "\n",
    "As we mentioned, [Amazon offers advice about voice interfaces and designing conversations](https://developer.amazon.com/designing-for-voice). \n",
    "They suggest you begin with the purpose of your bot and then form stories about your users, what makes them interact with your interface -- \"what people need to and can do.\" (Note that on the Alexa platforms, the voice interfaces you author are referred to as \"skills\" - presumably meaning we are teaching Alexa a skill and that the interface is teaching us to behave in a particular way.\n",
    "\n",
    ">**Identify the purpose and capabilities**\n",
    "<br>\n",
    "Describe one or more scenarios in which people will find your bot useful and desirable. Determine the capabilities of the bot by asking the following questions:\n",
    "* What is the purpose of the bot? Why will people want to use it?\n",
    "* What will the person be doing before, during, and after interacting with the bot?\n",
    "* What will people get from the bot that they cannot get another way?\n",
    "<br><br>\n",
    "\n",
    ">**Identify the user stories**\n",
    "<br>\n",
    "Based on the purpose and capabilities of the bot, identify individual steps and actions.\n",
    "* What can a user do, or not do, with the bot?\n",
    "* What information is the person expected to have available?\n",
    "* What are the ways a user can invoke the bot?\n",
    "* What features directly support the purpose?\n",
    "* Is there information that you need from other experiences, for example from a website or from a mobile app?\n",
    "\n",
    "They then ask you to outline basic scripts that \"show the conversation betwen the user and Alexa, like in a movie or a play.\" [Have a look at their guidelines and samples here.](https://developer.amazon.com/designing-for-voice/design-process/) They close the design process by outlining what you need to do to expand your basic scripts to fully articulate your application, getting prepared for when users don't act in the ways you expect.\n",
    "\n",
    "As one formulates a script, it might be good to spend some time thinking about *what constitutes **identifiable elements** of \"conversation\"*. We can then, translate these concepts into code. Again, we are not trying to have these bots \"pass\" for human, but instead be able to carry out basic conversational structure to get a task done, say. Interestingly, however, people will try to converse with a bot EVEN IF they know that the bot's soul purpose is clearly transactional. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "| Element of Conversation | Possible Techniques to Compute/ Quantify |\n",
    "| ------ | ----------- |\n",
    "|1. Notifications/ Recalling relevant things   |  Time Series Analysis, Alerting, Keyword caches |\n",
    "|2. Learning topics in context | Topic Mining/Modeling - extract the topic from the words in text |\n",
    "|3. Understanding Social Networks (offline and online)  | Network Science, the study of the structure of how things are connected and how information flows through it |\n",
    "|4. Responding to Emotion  | Sentiment Analysis\n",
    "|5. Having Episodic Memory  | Some kind of graphical model, [see Aditi's data post](https://medium.com/@aditinair/episodic-memory-modeling-for-conversational-agents-7c82e25b06b4#.9k65cziqw). |\n",
    "|6. Portraying Personality  | Decision Tree, which is a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Scripted Bots, Decision Trees and Hybrids**\n",
    "\n",
    "The simplest bots are scripted bots -- like ELIZA.  Their entire interaction is hard-coded (the “script”) that determines what the bot can and cannot do.  The “script” is a [decision tree](https://en.wikipedia.org/wiki/Decision_tree) where responding to one question takes you down a specific path, which opens up a new, pre-determined set of possibilities.\n",
    "\n",
    "For example, here's how you could design dialogue for a bot that helps you decide if you should have a cookie:\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src= \"http://static.twentytwowords.com/wp-content/uploads/cookie.gif\" style=\"width: 40%;\"/>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "In hybrid bots, some part of the interaction is driven by scripts (pre-written) but the majority is driven by an algorithm that isn't necessarily hardcoded. Instead, the model is instead generated from the current state of the data and then fitted into a conversation template, making it sound like a natural language response. This method can lead to hybrid bots, or fully automated ones. We will see ELIZA shortly, and here is an example of a fully automated bot - [NYTimes Minus Contex](https://twitter.com/NYTMinusContext).\n",
    "\n",
    "As Natural Language Processing becomes smarter, we will be able to do more fun things with bots at scale. The two key areas that is making lots of progress is (1) NL understanding: i.e. figuring out what the chat message means in context, and (2) NL Generation, i.e. generate a NL report from data (think about baseball or financial reports written by AI).\n",
    "\n",
    "**Some basic principles**\n",
    "\n",
    "In consulting a number of online guides like the text \n",
    "[Designing Bots](http://shop.oreilly.com/product/0636920057741.do) or a number of online blog posts \n",
    "[here](https://voiceui.fjordnet.com/), [here](https://careerfoundry.com/en/blog/ux-design/ultimate-guide-to-voice-ui-design) and [here](https://www.altexsoft.com/blog/business/a-comprehensive-guide-to-chatbots-best-practices-for-building-conversational-interfaces/), we found considerable consistency in approach. \n",
    "\n",
    "Most recommend defining clearly what you want your skill to do and to map out the flow of a person's conversation with the bot. The tools like decision trees will help you here. There is also a concern with the \"easiest\" way to do something. People, they suggest, don't want to listen to menus like you would in a phone tree, but instead they want things to play out in an order that makes sense. They also suggest endowing your bot with a personality... I suppose we should talk about that.\n",
    "\n",
    "We are going to start with a simple bot that is entirely rule based and does not learn from its interactions at all. We will work our way to the ELIZA bot. Now, this kind of bot usually operates by looking for simple patterns of language tht its partner is using. We are going to spend some time with a language for specifying patterns. This language works in Python, JAVA, JavaScript, R, you name it. It's general and powerful. \n",
    "\n",
    "### Regular Expressions ###\n",
    "\n",
    "<img src=https://imgs.xkcd.com/comics/regular_expressions.png width=400>\n",
    "\n",
    "In this portion of class, we are going to work with a \"language\" for expressing patterns in text. By \"pattern\" I mean specifying repetitions of symbols -- words or punctuation or sequences of numbers or any combination of these. Given a collection of text, for example, regular expressions might help you find dates or telephone numbers or URLs or email addresses -- all of these obey certain formatting rules. \n",
    "\n",
    "Regular expressions, then, are a way to describe these formatting rules so that we can search a body of text for them. Sometimes we are doing this because we want to find lists of facts about people (email addresses and their telephone numbers, say), creating structured data out of unstructured data (a common theme in this class). And sometimes we appeal to regular expressions because they help us in the act of \"cleaning\" data -- we might be given a date column in a data set that contains dates in two different formats (y-m-d and m/d/y, say) and we need to transform them into just one consistent format throughout. \n",
    "\n",
    "The patterns we express might also be about content. Can we detect the gender of sources? Can we find new memes in a stack of text? Unlike the proto-natural language processing we saw with TextBlob, regular expressions deal with words as patterns of characters. There is no understanding here about parts of speech or grammar. Just patterns of symbols -- characters, numbers, and emoji, even.\n",
    "\n",
    "**Trump's State of the Union Address**\n",
    "\n",
    "To explain how regular expressions work, we will look at a large collection of text -- the transcript of the SOTU from January. Lots of things were discussed and we can sort through topics, his speech patterns and so on.\n",
    "\n",
    "[The full transcript is here](https://www.whitehouse.gov/briefings-statements/remarks-president-trump-state-union-address-3/)\n",
    "\n",
    "[A file with one line per sentence is here](https://raw.githubusercontent.com/computationaljournalism/columbia2020/master/data/2020_sotu_sentences.txt)\n",
    "\n",
    "You can download the file in a browser window and save it to your computer or you can use the `requests` package to access the file from Python directly. You can choose either but for now, let's download the file and read it in directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file and read in the contents. recall\n",
    "# that this will take each line in the file and make\n",
    "# it an entry is a list. so the entire sotu is now a list\n",
    "# of strings, one string per sentence spoken.\n",
    "\n",
    "sentences = open(\"2020_sotu_sentences.txt\").readlines()\n",
    "\n",
    "print(\"The object 'sentences' is of type\", type(sentences))\n",
    "print(\"There are\", len(sentences), \"sentences in the list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a slice with the first five entries\n",
    "# (those having index 0, 1, 2, 3 and 4)\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside: List comprehensions**\n",
    "\n",
    "Notice that each sentence has a \"newline\" at the end of it, the `\\n` character. This is actually a common problem so it's worth mentioning. When you read in HTML, for example, the format doesn't care if you specify a heading like this\n",
    "    \n",
    "    <h1>A title</h1>\n",
    "\n",
    "or like this\n",
    "\n",
    "    <h1>         A title            </h1>\n",
    "    \n",
    "or like this\n",
    "\n",
    "    <h1>\n",
    "              A\n",
    "                    title\n",
    "                                 </h1>\n",
    "\n",
    "So we are routinely needing to tidy up text to make it more readable for a human, and to provide it with a bit of reglarity so any automated text processing is cleaner. This will happen with just about any data you come across -- some kind of regularizing is going to be needed, especially with text.\n",
    "\n",
    "The pretext of cleaning data also gives us a chance to review something precious. We can remove the newlines from the end of each sentence using our friend the 'list comprehension.' We might do something like the following if we had to use a loop. It goes over each sentence and strip()'s off the whitespace from the start and end of the string. Whitespace includes spaces and tabs and newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = []\n",
    "\n",
    "for s in sentences:\n",
    "    clean_s = s.strip()\n",
    "    new_sentences.append(clean_s)\n",
    "    \n",
    "new_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference? The `\\n`'s are gone!\n",
    "\n",
    "To sum, we iterate through the list of sentences. Each sentence is `strip()`'d, has all the \"white space\" removed from its front and back end, and then appended to the new_sentences list. I hope you agree that this is kind of clunky notation. \n",
    "\n",
    "A \"list comprehension\" is a cleaner way to accomplish the same thing. So, let's reread the data and apply this new code construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the speech\n",
    "sentences = open(\"2020_sotu_sentences.txt\").readlines()\n",
    "\n",
    "# use a list comprehension to strip out the newlines\n",
    "new_sentences = [s.strip() for s in sentences]\n",
    "\n",
    "new_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second expression above says that we cycle through all the elements in `sentences`, letting the variable name `s` represent each one in turn. The first element, for example, becomes the start of a new list, and it has had `.strip()` applied to it. The second element is then `strip()`'d and stored in the new list and so on. As you can see, a list comprehension reads like our loop in the previous cell and behaves similarly -- but it is syntactically nicer. \n",
    "\n",
    "You can also limit the number of results included in the new list by adding an `if` clause -- a logical expression. As the list comprehension is running through the elements of the old list, it can chose whether or not to incude it in the new list via a logical expression. \n",
    "\n",
    "Suppose, for example, we want to keep only sentences that contain the word \"wall\". In terms of programming, we can use the operator `in`. We've seen this logical operator before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"anything\" in  'America is the place where anything can happen.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"NASA\" in  'It’s called the Space Force.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this, in the expression below we run through each entry in the list `sentences`, labeling them `s` in turn, and keeps only (the cleaned versions) those with at least one occurrence of the word \"wall\". (Here we don't save the new, reduced and transformed list -- we just have a look at it.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s.strip() for s in sentences if \"wall\" in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to make a new list in a loop we might do the following. Hopefully you see the code above is slicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_sentences = []\n",
    "\n",
    "for s in sentences:\n",
    "    clean_s = s.strip()\n",
    "    if \"wall\" in clean_s:\n",
    "        wall_sentences.append(clean_s)\n",
    "        \n",
    "wall_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, back to list comprehensions -- new lists from old with a syntax that's a lot cleaner to read than a loop. We'll be using them for the remainder of this lesson. Keep in mind, however, that while we are using them for text, they can be used for any list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of some numbers\n",
    "x = [2,5,4,7,8,2,4,5]\n",
    "\n",
    "# a list comprehension that just keeps two times\n",
    "# the entries that are larger than 3\n",
    "[2*i for i in x if i>3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understand the example above. This construction is pretty powerful!\n",
    "\n",
    "### A few transcripts and an introduction to Regular Expressions ###\n",
    "\n",
    "Just so it's not all about Trump, we've also pulled all the sentences spoken by [Joe Biden](https://raw.githubusercontent.com/computationaljournalism/columbia2020/master/data/biden_debate.txt) and [Bernie Sanders](https://raw.githubusercontent.com/computationaljournalism/columbia2020/master/data/sanders_debate.txt) in the South Carolina debate. As with the SOTU file, this has one sentence per line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOTU sentences\n",
    "sentences = open(\"2020_sotu_sentences.txt\").readlines()\n",
    "sotu_sentences = [s.strip() for s in sentences]\n",
    "\n",
    "# Biden's debate sentences\n",
    "sentences = open(\"biden_debate.txt\").readlines()\n",
    "biden_sentences = [s.strip() for s in sentences]\n",
    "\n",
    "# Sanders' debate sentences\n",
    "sentences = open(\"sanders_debate.txt\").readlines()\n",
    "sanders_sentences = [s.strip() for s in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python implements the regular expression search framework through a package called `re` (aptly named). We are going to make use of the `search()` function in this package. It takes a pattern definition (a regular expression) and searches for it in a string, returning every match it finds. You can use this in a list comprehension because when a `search()` finds a regular expression pattern it is treated as `True` in an `if` statement. When it can't find the pattern, it is treated as `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Literals** \n",
    "\n",
    "As a way of specifying patterns, let's start with so-called \"literals\" -- these characters just match themselves. For example, the literal *\"wall\"* matches the following sentences from Trump’s transcript. This should be equivalent to the results we had by using the operator `in` in our loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(\"wall\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or here we search for \"billionaires\" in Sanders' sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sanders_sentences if search(\"billionaires\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we don't care about the case of the text we are matching. We can add a flag to the regular expression to explicitly ignore the case of the literals we are searching for. Tweeting is not a particularly grammatical exercise, so this option might be good to add. It's a flag we can import from `re`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import IGNORECASE\n",
    "\n",
    "[s for s in biden_sentences if search(\"look\",s,IGNORECASE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the literal *\"wall\"* with a search for *\"immigration\"* in the SOTU sentences. Do you find any sentences matching this pattern? What other searches like this might you do to highlight sentences about immigration? Or other topics that this search suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we were interested in \"media\" we might look for the **literal string** consisting of the letters m-e-d-i-a. \n",
    "\n",
    "See what we get..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(\"media\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, well, that's not what we wanted at all. So, how do we get just the word \"media\"? Let's take a moment and write down the kinds of patterns in text we might be interested in finding, either from this speech or the debate texts or from your reporting or other work. What sorts of things do you have to specify? I mean word boundaries seem like a good idea so we can differentiate \"media\" from \"immediate\". What else do you need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get us to more complex searches, we need some way to express these ideas. And that's where metacharacters come to the rescue!\n",
    "\n",
    "**In Walks Metacharacters**\n",
    "\n",
    "Any character except for [ ]\\\\^\\$.|?\\*+( )\\{ and \\} can be used to specify a literal -- they match a single instance of themselves. The string *\"wall\"* represented a series of literals and to have a match we need to find a \"w\" followed by an \"a\" followed by an \"l\" and so on. The non-literals, on the other hand, are known as **metacharacters** and are used to specify much more complicated text patterns.\n",
    "\n",
    "They help us specify \"whitespace,\" word boundaries, sets or classes of literals, the beginning and end of a line, and various alternatives (\"war\" or \"peace\"). For example **^ represents the start of a line.** Let's look at what we get by searching the SOTU for a pattern than includes this character.\n",
    "\n",
    "*(We are now going to preface our strings representing regular expressions with the letter `r`. We have seen `u` before to mean Unicode. Here `r` means a \"raw\" string. Basically it tells Python that every character is to be interpreted as it is. We have seen that `\\n` in a string means a single character, newline. In a raw string, `\\n` is interpreted as two characters, a backslash and an \"n\". This will be important and is really a way around the fact that regular expressions and Python use metacharacters to build things like newlines or  to represent the beginning of a sentence.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sanders_sentences if search(r\"^I think\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a new sentence starter and see what you find..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Help**\n",
    "\n",
    "To interpret what a regular expression is doing, we can use a special tool from [regexper.com](http://regexper.com/). It takes regular expressions and renders them graphically so you can get a better sense of how the machinery is functioning. For example, here is the display for our *\"^I have\"* example.\n",
    "\n",
    "[Graphical view of the pattern \"^I think\"](https://regexper.com/#%5EI%20think)\n",
    "\n",
    "You see a window where you can change the regular expression and then a graphical interpretation of what you've asked for. This is an extremely handy tool. (Notice that you don't have to include the quotes or the `r` in the regexper.com interface.) \n",
    "\n",
    "Now, if specifying the start of a line is important, having a special character for the end of a line is likely to be handy also. **The \\$ represents the end of a line.** Consider the pattern *\"it.\\$\"*. Here are the lines it matches the SOTU. Do you notice anything odd here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in biden_sentences if search(r\"it.$\",s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(r\"it.$\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next expression, we look for lines that end *\"turn.$\"* but find only one sentence and it ends with a question mark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sanders_sentences if search(r\"turn.$\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here? Well, the dot, \".\", is a metacharacter and represents a wildcard. It is used to refer to any character. So, *turn.\\$* will match lines that end in \"turn.\" or \"turn?\" or even \"turn9\" (should the transcriber be typing sloppily one day). Have a look at this at regexper.com.\n",
    "\n",
    "[Graphical view of the pattern \"turn.\\$\"](http://regexper.com/#turn.%24)\n",
    "\n",
    "Putting a backslash \\\\ before one of the special metacharacters [ ] \\\\^\\$/?\\*+()\\{ and \\} lets us include these in a pattern as literals -- in technical terms, we have \"escaped\" the special meaning of these characters and they return to their literal meanings. \n",
    "\n",
    "Consider the pattern \"\\\\\\\\$2\". With the backslash, \\$ no longer means the end of a line. We have returned the dollar sign to its literal meaning and the following lines match from the Trump transcript. \n",
    "\n",
    ">Therefore, we recently imposed tariffs on $250 billion of Chinese goods — and now our Treasury is receiving billions of dollars a month from a country that never gave us a dime\n",
    "\n",
    "And to bring the point home, look at the following.\n",
    "\n",
    "[Graphical view of the pattern \"\\\\\\\\$2\"](http://regexper.com/#%5C%242)\n",
    "\n",
    "So, given this, what do we need to do to match sentences ending with the word \"country\" followed by a period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A character class matches a single character out of all the possibilities contained in brackets, [  ]** — There are certain rules that apply when specifying these classes that we’ll get to in a second. Let's look at the pattern *\"[Tt]onight\"* and see what lines it matches in the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(r\"[Tt]onight\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Graphical view of the pattern \"[Tt]onight\"](http://regexper.com/#%5BTt%5Donight)\n",
    "\n",
    "Keep in mind that while there might be lots of options in the square brackets, we are only trying to match one character out of this group. The graphical display makes this clear. We'll talk about specifying more than one match in a few minutes.\n",
    "\n",
    "In terms of the rules that work within character classes, you can specify a range of letters [a-z] or [A-Z] or numbers [0-9] — Keep in mind that the order within the character class doesn’t matter, it specifies a bag of characters from which we select one item. Let's look at the pattern *\"[0-9] years\"* and see which sentences it will match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(r\"[0-9] years\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Graphical view of the pattern \"[0-9] years\"](http://regexper.com/#%5B0-9%5D%20years)\n",
    "\n",
    "It's important to keep in mind what's being matched here. The expression *\"[0-9] years\"* will match \"5 years\" in the sentence that started \"CJ served 15 years in the Air Force\". The expression wants a number then a space then the word \"years\". Get it? \n",
    "\n",
    "**When used at the beginning of a character class ^ is also a metacharacter and it indicates matching characters NOT in the indicated class.** So the pattern *\"[^?.]\\$\"* will match sentences that don't end in a period or a question mark (you don't have to \"escape\" characters in a character class -- or between [ and ]). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(r\"[^?.]$\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a large number of quotes in this list. Maybe we should look for quoted statements next? Anyway, here is the graphical representation of the expression.\n",
    "\n",
    "[Graphical view of the pattern \"[^?.]\\$\"](http://regexper.com/#%5B%5E%3F.%5D%24)\n",
    "\n",
    "Continuing on our survey of metacharacters, the **vertical bar \"|\" translates to “or”** — We can use it to combine expressions, the subexpressions being called alternatives. The expression *\"good|bad\"* will match these lines from transcript file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(r\"good|bad\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll jump ahead just briefly and say that we can solve the problem of matching \"goodness\" and \"badly\" when all we want are the words \"good\" or bad\". Some collections of characters, some \"character classes\" are used so often that they are given special notation. For example `\\w` is a word character and `\\b` represents a character class of \"word boundaries\". Here's a (not elegant but works) way to say you want \"good\" or \"bad\" alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(r\"\\bgood\\b|\\bbad\\b\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will give a complete set of character classes at the end of this section.\n",
    "\n",
    "Returning to choices, of course we can join several alternatives together. Consider *\"year|month|day\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sanders_sentences if search(r\"day|month|year\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, here we see a lot of matches to patterns like \"birthday\" or \"someday\". Both contain the literal *\"day\"* but they might not be what we had in mind. \n",
    "\n",
    "[Graphical view of the pattern \"year|month|day\"](http://regexper.com/#year%7Cmonth%7Cday)\n",
    "\n",
    "Oh and the alternatives separated by \"|\" can be any real expressions and not just literals. Here we ask for time or money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(\"[0-9] year|\\$[0-9]\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, regexper.com to help us out.\n",
    "\n",
    "[Graphical view of the pattern \"[0-9] year|\\$[0-9]\"](https://regexper.com/#%5B0-9%5D%20year%7C%5C%24%5B0-9%5D)\n",
    "\n",
    "**Subexpressions are often contained in parentheses (more metacharacters) to constrain the\n",
    "alternatives in some way.** For example *\"^(I will|I am)\"* matches either expression, but at the start of a sentence. \n",
    "\n",
    "Later we will see that we can identify each subexpression separately,allowing us to extract (or capture) the content they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(\"^(I am|I have)\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the graphical representation -- notice the new reference to groups that are formed by the parentheses.\n",
    "\n",
    "<a href=https://regexper.com/#%5E%28I%20have%7CI%20am%29>Graphical view of the pattern \"^(I have|I am)\"</a>\n",
    "\n",
    "We're building up quite a vocabulary. Try a more complex expression on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we leave this, let's use the shorthand \\\\b  for word boundaries and our parentheses construction to match what we really wanted with our original search a few cells back, *\"\\b(day|month|year)\\b\"*. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(r\"\\b(day|month|year)\\b\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The question mark indicates that the indicated expression is optional.** The expression *\"George( W\\\\.)? Bush\"* will match references to “George W. Bush” or just “George Bush”.\n",
    "\n",
    "<a href=http://regexper.com/#George(%20W%5C.)%3F%20Bush>Graphical view of the pattern \"George( W\\\\.)? Bush\"</a>\n",
    "\n",
    "**The \\* and + signs are metacharacters used to indicate repetition** — the \\* means “any number, including zero, of the item” and + means “at least one of the item”. So we can specify clauses after a colon with the following regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sotu_sentences if search(r\":.+$\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make this seem a bit more practical, we are going to consider another data source. You can download some of it, but it's big. It's essentially all of Jeb Bush's emails while he was in office in Florida. I mean literally in `mbox` format. The site is show here via the Internet Archive...\n",
    "<br><br>\n",
    "<img src=https://github.com/computationaljournalism/columbia2018/raw/master/images/jb2.jpg style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "... because this was such a bad idea, they took the site down quickly. \n",
    "<br><br>\n",
    "<img src=https://github.com/computationaljournalism/columbia2018/raw/master/images/jb1.jpg style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "Why a bad idea? Well, no one masked any possibly sensitive data from the emails. So it's easy to find phone numbers or social security numbers or military ID's in these text files.\n",
    "\n",
    "For example, to grab phone numbers, what regular expression might we use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your expression here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For social security numbers or phone numbers we could use this expression *\"[0-9]+-[0-9]+-[0-9]+\"*. Why? Here's a series of lines that match this pattern from Jeb's emails.\n",
    "\n",
    ">Phone: 407-240-1891<br><br>In reference to your letter dated october 29, 1998 in which you offer to help me with my inmigration question, i am a us citizen who is petition for my husband (a mexican citizen) petition #SRC-98-204-50114 his name is FRANCISCO JAVIER CORTEZ HERNANDEZ.<br><br>Fax: 407-888-2445<br><br>Pager: 850-301-8072<br><br>Cell: 407-484-8167<br><br>The Reverned uses his pager# 813-303-4726 to get in contact with, or you may email\n",
    "and I will get in touch with him. <br><br>\n",
    "\n",
    "And from regexper.com... \n",
    "\n",
    "<a href=http://regexper.com/#%5B0-9%5D%2B-%5B0-9%5D%2B-%5B0-9%5D%2B>Graphical view of the pattern \"[0-9]+-[0-9]+-[0-9]+\"</a>\n",
    "\n",
    "In words, we are looking for one or more numbers followed by a hyphen, followed by one or more numbers, and then another hyphen, and finally one or more numbers.\n",
    "\n",
    "**The curly braces \\{ and \\} are referred to as interval quantifiers** — they let us specify the exact number of occurences of a pattern, its minimum, maximum or an acceptable range. For a Social Security Number we might want \"[0-9]{3}-[0-9]{2}-[0-9]{4}\", for example - three numbers, a hyphen, two numbers, a hyphen then four numbers.  \n",
    "\n",
    "<a href=https://regexper.com/#%5B0-9%5D%7B3%7D-%5B0-9%5D%7B2%7D-%5B0-9%5D%7B4%7D>View of the pattern \"[0-9]{3}-[0-9]{2}-[0-9]{4}\"</a>\n",
    "\n",
    "Here's the full list of what you can do with the curly braces as metacharacters. \n",
    "<table>\n",
    "          <tr>\n",
    "            <th>Expression</th>\n",
    "            <th>What does it mean?</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{3}</td>\n",
    "            <td>Looks for 3 occurences of a pattern</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{,3}</td>\n",
    "            <td>Matches at most 3 occurrences</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{3,}</td>\n",
    "            <td>Matches at least 3 occurrences</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{3,5}</td>\n",
    "            <td>Matches between 3 and 5 occurrences</td>\n",
    "          </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, how would we skim these emails for specific kinds of numbers? Credit card numbers? Phone numbers? VIN numbers?\n",
    "\n",
    "**Groupings.** In most implementations of regular expressions, the parentheses not only limit the scope\n",
    "of alternatives divided by a “|”, but also can be used to “remember” text matched by the\n",
    "subexpression enclosed. We refer to the matched text with \\1, \\2, etc., depending on how many parenthese we have. \n",
    "\n",
    "As an example, the expression\n",
    "*\" ([a-zA-Z]+) \\1 \"* will match these lines in Jeb Bush’s inbox from January of 2000.\n",
    "\n",
    ">I feel this is a **win win** situation for the Governor, the Reverend and the people that need help.<br><br>I insisted **that that** be the outcome in that court and that we did not recede from that position.<br><br>I guess you're embarrassed **that that** line got out.<br><br>\n",
    "\n",
    "The pattern is asking for repeated words. We highlighted them in the text above. Also have a look at the graphical representation of this regular expression.\n",
    "\n",
    "<a href=http://regexper.com/#%20(%5Ba-zA-Z%5D%2B)%20%5C1%20>Graphical view of the pattern \" ([a-zA-Z]+) \\1 \"</a>.\n",
    "\n",
    "**Substitution**\n",
    "\n",
    "Groupings are also helpful when you want to make substitutions. We have already seen that string types offer you the opportunity to replace text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'San Diego used to have the most illegal border crossings in the country..'\n",
    "s.replace(\"Diego\",\"Francisco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `re` package includes a function `sub` that lets you act on groups. Here we define a group to be a dollar value and extract it. With this kind of construction, you can see how you might start to pull structured information from unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "s = \"At the same time, she rallied her community and raised more than $40,000 for the fight against cancer.\"\n",
    "\n",
    "# pull out the dollar value\n",
    "sub(r\".*\\$([0-9,]+).*\",r\"\\1\",s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To Sum**\n",
    "\n",
    "The presentation here is meant to give you a flavor of how regular expressions are structured; you have seen the major metacharacters and to use them to create patterns. Below I provide a useful cheat sheet to remember what the different metacharacters mean and what some of the useful shorthand character classes are. In addition, I can recommend [an interactive cheat sheet](https://www.debuggex.com/cheatsheet/regex/python), and the site [http://www.regular-expressions.info/](http://www.regular-expressions.info/) is also an excellent resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metacharacters**\n",
    "\n",
    "<table>\n",
    "          <tr>\n",
    "            <th>Metacharacter</th>\n",
    "            <th>What does it do?</th>\n",
    "            <th>Examples</th>\n",
    "            <th>Matches</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>^</td>\n",
    "            <td>Matches beginning of line</td>\n",
    "            <td>^abc</td>\n",
    "            <td>abc, abcdef.., abc123</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\$</td>\n",
    "            <td>Matches end of line</td>\n",
    "            <td>abc\\$</td>\n",
    "            <td>my:abc, 123abc, theabc</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>.</td>\n",
    "            <td>Match any character</td>\n",
    "            <td>a.c</td>\n",
    "            <td>abc, asg, a123c</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>[...]</td>\n",
    "            <td>Matches one character contained in brackets</td>\n",
    "            <td>[abc]</td>\n",
    "            <td>a,b, or c</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>[^...]</td>\n",
    "            <td>Matches one character not contained in brackets</td>\n",
    "            <td>[^abc]</td>\n",
    "            <td>xyz, 123, 1de</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>[a-z]</td>\n",
    "            <td>Matches one character between 'a' and 'z'</td>\n",
    "            <td>[b-z]</td>\n",
    "            <td>bc, mind, xyz</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\*</td>\n",
    "            <td>Matches character before \\* 0 or more times</td>\n",
    "            <td>ab\\*c</td>\n",
    "            <td>abc, abbc, ac</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>+</td>\n",
    "            <td>Matches character before + one or more times</td>\n",
    "            <td>a+c</td>\n",
    "            <td>ac, aac, aaac,</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>?</td>\n",
    "            <td>Matches the character before the ? zero or one times. Also, used as a non-greedy match</td>\n",
    "            <td>ab?c</td>\n",
    "            <td>ac, abc</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{x}</td>\n",
    "            <td>Match exactly 'x' number of times</td>\n",
    "            <td>(abc){2}</td>\n",
    "            <td>abcabc</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{x,}</td>\n",
    "            <td>Match 'x' number of times or more</td>\n",
    "            <td>(abc){2,}</td>\n",
    "            <td>abcabc, abcabcabc</td>\n",
    "          </tr>\n",
    "           <tr>\n",
    "            <td>{,x}</td>\n",
    "            <td>Match up to 'x' number of times</td>\n",
    "            <td>(abc){2,}</td>\n",
    "            <td>abcabc, abcabcabc</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{x,y}</td>\n",
    "            <td>Match between 'x' and 'y' times.</td>\n",
    "            <td>(a){2,4}</td>\n",
    "            <td>aa, aaa, aaaaa</td>\n",
    "          </tr>\n",
    "           <tr>\n",
    "            <td>|</td>\n",
    "            <td>OR operator</td>\n",
    "            <td>abc|xyz</td>\n",
    "            <td>abc or xyz</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>(...)</td>\n",
    "            <td>Capture anything matched</td>\n",
    "            <td>(a)b(c)</td>\n",
    "            <td>Captures 'a' and 'c'</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>(?:...)</td>\n",
    "            <td>Non-capturing group</td>\n",
    "            <td>(a)b(?:c)</td>\n",
    "            <td>Captures 'a' but only groups 'c'</td>\n",
    "          </tr>\n",
    "           <tr>\n",
    "            <td>\\</td>\n",
    "            <td>Escape the character after the backslash; or create a special sequence (like word boundaries, \\b, or a character representing a space, \\s.</td>\n",
    "            <td>a\\sc</td>\n",
    "            <td>a c</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "\n",
    "The special \"metacharacters\" () [] {} ^ \\$ . | \\* + ?  and \\\\ become \"literals\" again if you put a \\\\ in front of them -- That is, \\\\. matches a period and is no longer the wild card. We say we have \"escaped\" the metacharacter.\n",
    "\n",
    "**Shorthand character classes**\n",
    "\n",
    "<table>\n",
    "          <tr>\n",
    "            <td>\\d</td>\n",
    "            <td>Match any digit (0-9)</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\D</td>\n",
    "            <td>Match any non digit</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td >\\t</td>\n",
    "            <td>Match a tab</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\n</td>\n",
    "            <td>Match a new line</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\r</td>\n",
    "            <td>Match a carriage return</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\s</td>\n",
    "            <td>Matches a space character (space, \\t, \\r, \\n)</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\S</td>\n",
    "            <td>Matches any non-space character </td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\b</td>\n",
    "            <td>Word boundary</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\B</td>\n",
    "            <td>Non word boundary</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\w</td>\n",
    "            <td>Matches any one word character [a-zA-Z_0-9]</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\W</td>\n",
    "            <td>Matches any one non word character</td>\n",
    "          </tr>\n",
    "          </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Coming Age of Conversational Bots\n",
    "--------------------------------------\n",
    "<hr>\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1000/1*-uuhR1UX709LfUnDiS30Rg.png\"  style=\"width: 65%;\"/>\n",
    "<br>\n",
    "\n",
    "We start with the modern chatbot. FastCompany  published a nice history of  a particular kind of software robot: [How The New, Improved Chatbots Rewrite 50 Years Of Bot History](http://www.fastcompany.com/3059439/why-the-new-chatbot-invasion-is-so-different-from-its-predecessors). Chatbots are really a conversation-based interfaces to services of various kinds. Sometimes the logic behind their inner workings is incredibly complex, but other times their operation is very service-oriented and shallow. Sometimes they are reading from a script, sometimes machine learning helps direct responses.\n",
    "\n",
    "The FastCompany article makes the point that while strands of artificial intelligence research has been obsessed with making a both that was believably human (or perhaps with the potential for one), the latest incarnations of these programs exist \"to help you get things done.\" They have grown plentiful using the scale of new platforms (Facebook, Twitter, and so on) and are fit tidily into their business interests.\n",
    "\n",
    "Here's a snippet.\n",
    "\n",
    ">But over the past few years, chatbots have made a comeback. With advancements in processing power, bots now have a better ability to interpret natural language and learn from users over time. Just as importantly, big companies like Facebook, Apple, and Microsoft are now eager to host our interactions with various services, and offer tools for developers to make those services available. Chatbots easily fit into their larger business models of advertising, e-commerce, online services, and device sales. Meanwhile, services that want to reach hundreds of millions of customers on a platform like Messenger will be helping to write the chat scripts.\n",
    "<br><br>\"A lot of the things that were barriers to us back then are no longer barriers to us today because of the evolution of the way technology works,\" Hoffer says.\n",
    "<br><br>\n",
    "Crucially, these bots are meant to be useful out of the gate, ... they no longer need conversation as a crutch for mass adoption. Sure, Apple’s Siri knows how to break the ice with a few jokes, but it largely exists to help you get things done. Rival assistants from Google and Amazon don’t exhibit much personality at all. Utility is winning out because the technology allows for it.\n",
    "\n",
    "The article ends with a comment about early artificial intelligence researcher Joseph Weizenbaum. Weizenbaum created something called ELIZA, a computer program that was modeled after a psychiatrist (or an \"active listener\"). \n",
    "\n",
    ">If the latest round of chatbots succeed, they might prove that Weizenbaum, the creator of ELIZA, was right all along. These machines are not warm and cuddly replacements for the human intellect. They’re just another set of tools—an evolution of the apps that have served us for years.\n",
    "\n",
    "As an aside, Weizenbaum didn't create ELIZA as a state of the art conversational program. He was, in fact, troubled by its positive reception, and later in life he wrote about the limits of artificial intelligence. The passage below is from his 1976 text [Computer power and human reason](https://en.wikipedia.org/wiki/Computer_Power_and_Human_Reason). He closes the third chapter with this image.\n",
    "\n",
    ">Sometimes when my children were still little, my wife and I would stand over them as they lay sleeping in their beds. We spoke to each other only in silence, rehearsing a scene as old as mankind itself. It is as Ionesco told his journal: ‘Not everything is unsayable in words, only the living truth.\n",
    "\n",
    "Beautiful, right? For a data class, it's a great reminder that data will always exist at distance from lived experience. We can try to pile more and more data on a given situation or phenomenon. But no matter how big our data gets, we are still missing something. That's why we've been stressing how your choice of data is a creative act.\n",
    "\n",
    "Before we startup ELIZA, our dear friend Suman has listed out a number of identifiable elements to think about when you are designing a conversation. Again, not all of these will apply as we might be very functionally-oriented, but they are something to remember.\n",
    "\n",
    "#### Some Identifiable Elements of Conversation:\n",
    "\n",
    "| Element of Conversation | Possible Techniques to Compute/ Quantify |\n",
    "| ------ | ----------- |\n",
    "|1. Notifications/ Recalling relevant things   |  Time Series Analysis, Alerting, Keyword caches |\n",
    "|2. Learning topics in context | Topic Mining/Modeling - extract the topic from the words in text |\n",
    "|3. Understanding Social Networks (offline and online)  | Network Science, the study of the structure of how things are connected and how information flows through it |\n",
    "|4. Responding to Emotion  | Sentiment Analysis\n",
    "|5. Having Episodic Memory  | Some kind of graphical model, [see Aditi's data post](https://medium.com/@aditinair/episodic-memory-modeling-for-conversational-agents-7c82e25b06b4#.9k65cziqw). |\n",
    "|6. Portraying Personality  | Decision Tree, which is a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. |\n",
    "\n",
    "\n",
    "\n",
    "**ELIZA**\n",
    "\n",
    "Anyway, today we are going to work on the basics of a chatbot. Below we have the ELIZA program in Python form. Execute it and interact. You type \"quit\" to get out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import match, IGNORECASE\n",
    "from random import choice\n",
    " \n",
    "reflections = {\n",
    "    \"am\": \"are\",\n",
    "    \"was\": \"were\",\n",
    "    \"i\": \"you\",\n",
    "    \"i'd\": \"you would\",\n",
    "    \"i've\": \"you have\",\n",
    "    \"i'll\": \"you will\",\n",
    "    \"my\": \"your\",\n",
    "    \"are\": \"am\",\n",
    "    \"you've\": \"I have\",\n",
    "    \"you'll\": \"I will\",\n",
    "    \"your\": \"my\",\n",
    "    \"yours\": \"mine\",\n",
    "    \"you\": \"me\",\n",
    "    \"me\": \"you\"\n",
    "}\n",
    " \n",
    "actions = [\n",
    "    [r'I need (.*)',\n",
    "     [\"Why do you need {0}?\",\n",
    "      \"Would it really help you to get {0}?\",\n",
    "      \"Are you sure you need {0}?\"]],\n",
    " \n",
    "    [r'Why don\\'?t you ([^\\?]*)\\??',\n",
    "     [\"Do you really think I don't {0}?\",\n",
    "      \"Perhaps eventually I will {0}.\",\n",
    "      \"Do you really want me to {0}?\"]],\n",
    " \n",
    "    [r'Why can\\'?t I ([^\\?]*)\\??',\n",
    "     [\"Do you think you should be able to {0}?\",\n",
    "      \"If you could {0}, what would you do?\",\n",
    "      \"I don't know -- why can't you {0}?\",\n",
    "      \"Have you really tried?\"]],\n",
    " \n",
    "    [r'I can\\'?t (.*)',\n",
    "     [\"How do you know you can't {0}?\",\n",
    "      \"Perhaps you could {0} if you tried.\",\n",
    "      \"What would it take for you to {0}?\"]],\n",
    " \n",
    "    [r'I am (.*)',\n",
    "     [\"Did you come to me because you are {0}?\",\n",
    "      \"How long have you been {0}?\",\n",
    "      \"How do you feel about being {0}?\"]],\n",
    " \n",
    "    [r'I\\'?m (.*)',\n",
    "     [\"How does being {0} make you feel?\",\n",
    "      \"Do you enjoy being {0}?\",\n",
    "      \"Why do you tell me you're {0}?\",\n",
    "      \"Why do you think you're {0}?\"]],\n",
    " \n",
    "    [r'Are you ([^\\?]*)\\??',\n",
    "     [\"Why does it matter whether I am {0}?\",\n",
    "      \"Would you prefer it if I were not {0}?\",\n",
    "      \"Perhaps you believe I am {0}.\",\n",
    "      \"I may be {0} -- what do you think?\"]],\n",
    " \n",
    "    [r'What (.*)',\n",
    "     [\"Why do you ask?\",\n",
    "      \"How would an answer to that help you?\",\n",
    "      \"What do you think?\"]],\n",
    " \n",
    "    [r'How (.*)',\n",
    "     [\"How do you suppose?\",\n",
    "      \"Perhaps you can answer your own question.\",\n",
    "      \"What is it you're really asking?\"]],\n",
    " \n",
    "    [r'Because (.*)',\n",
    "     [\"Is that the real reason?\",\n",
    "      \"What other reasons come to mind?\",\n",
    "      \"Does that reason apply to anything else?\",\n",
    "      \"If {0}, what else must be true?\"]],\n",
    " \n",
    "    [r'(.*) sorry (.*)',\n",
    "     [\"There are many times when no apology is needed.\",\n",
    "      \"What feelings do you have when you apologize?\"]],\n",
    " \n",
    "    [r'Hello(.*)',\n",
    "     [\"Hello... I'm glad you could drop by today.\",\n",
    "      \"Hi there... how are you today?\",\n",
    "      \"Hello, how are you feeling today?\"]],\n",
    " \n",
    "    [r'I think (.*)',\n",
    "     [\"Do you doubt {0}?\",\n",
    "      \"Do you really think so?\",\n",
    "      \"But you're not sure {0}?\"]],\n",
    " \n",
    "    [r'(.*) friend (.*)',\n",
    "     [\"Tell me more about your friends.\",\n",
    "      \"When you think of a friend, what comes to mind?\",\n",
    "      \"Why don't you tell me about a childhood friend?\"]],\n",
    " \n",
    "    [r'Yes',\n",
    "     [\"You seem quite sure.\",\n",
    "      \"OK, but can you elaborate a bit?\"]],\n",
    " \n",
    "    [r'(.*) computer(.*)',\n",
    "     [\"Are you really talking about me?\",\n",
    "      \"Does it seem strange to talk to a computer?\",\n",
    "      \"How do computers make you feel?\",\n",
    "      \"Do you feel threatened by computers?\"]],\n",
    " \n",
    "    [r'Is it (.*)',\n",
    "     [\"Do you think it is {0}?\",\n",
    "      \"Perhaps it's {0} -- what do you think?\",\n",
    "      \"If it were {0}, what would you do?\",\n",
    "      \"It could well be that {0}.\"]],\n",
    " \n",
    "    [r'It is (.*)',\n",
    "     [\"You seem very certain.\",\n",
    "      \"If I told you that it probably isn't {0}, what would you feel?\"]],\n",
    " \n",
    "    [r'Can you ([^\\?]*)\\??',\n",
    "     [\"What makes you think I can't {0}?\",\n",
    "      \"If I could {0}, then what?\",\n",
    "      \"Why do you ask if I can {0}?\"]],\n",
    " \n",
    "    [r'Can I ([^\\?]*)\\??',\n",
    "     [\"Perhaps you don't want to {0}.\",\n",
    "      \"Do you want to be able to {0}?\",\n",
    "      \"If you could {0}, would you?\"]],\n",
    " \n",
    "    [r'You are (.*)',\n",
    "     [\"Why do you think I am {0}?\",\n",
    "      \"Does it please you to think that I'm {0}?\",\n",
    "      \"Perhaps you would like me to be {0}.\",\n",
    "      \"Perhaps you're really talking about yourself?\"]],\n",
    " \n",
    "    [r'You\\'?re (.*)',\n",
    "     [\"Why do you say I am {0}?\",\n",
    "      \"Why do you think I am {0}?\",\n",
    "      \"Are we talking about you, or me?\"]],\n",
    " \n",
    "    [r'I don\\'?t (.*)',\n",
    "     [\"Don't you really {0}?\",\n",
    "      \"Why don't you {0}?\",\n",
    "      \"Do you want to {0}?\"]],\n",
    " \n",
    "    [r'I feel (.*)',\n",
    "     [\"Good, tell me more about these feelings.\",\n",
    "      \"Do you often feel {0}?\",\n",
    "      \"When do you usually feel {0}?\",\n",
    "      \"When you feel {0}, what do you do?\"]],\n",
    " \n",
    "    [r'I have (.*)',\n",
    "     [\"Why do you tell me that you've {0}?\",\n",
    "      \"Have you really {0}?\",\n",
    "      \"Now that you have {0}, what will you do next?\"]],\n",
    " \n",
    "    [r'I would (.*)',\n",
    "     [\"Could you explain why you would {0}?\",\n",
    "      \"Why would you {0}?\",\n",
    "      \"Who else knows that you would {0}?\"]],\n",
    " \n",
    "    [r'Is there (.*)',\n",
    "     [\"Do you think there is {0}?\",\n",
    "      \"It's likely that there is {0}.\",\n",
    "      \"Would you like there to be {0}?\"]],\n",
    " \n",
    "    [r'My (.*)',\n",
    "     [\"I see, your {0}.\",\n",
    "      \"Why do you say that your {0}?\",\n",
    "      \"When your {0}, how do you feel?\"]],\n",
    " \n",
    "    [r'You (.*)',\n",
    "     [\"We should be discussing you, not me.\",\n",
    "      \"Why do you say that about me?\",\n",
    "      \"Why do you care whether I {0}?\"]],\n",
    " \n",
    "    [r'Why (.*)',\n",
    "     [\"Why don't you tell me the reason why {0}?\",\n",
    "      \"Why do you think {0}?\"]],\n",
    " \n",
    "    [r'I want (.*)',\n",
    "     [\"What would it mean to you if you got {0}?\",\n",
    "      \"Why do you want {0}?\",\n",
    "      \"What would you do if you got {0}?\",\n",
    "      \"If you got {0}, then what would you do?\"]],\n",
    " \n",
    "    [r'(.*) mother(.*)',\n",
    "     [\"Tell me more about your mother.\",\n",
    "      \"What was your relationship with your mother like?\",\n",
    "      \"How do you feel about your mother?\",\n",
    "      \"How does this relate to your feelings today?\",\n",
    "      \"Good family relations are important.\"]],\n",
    " \n",
    "    [r'(.*) father(.*)',\n",
    "     [\"Tell me more about your father.\",\n",
    "      \"How did your father make you feel?\",\n",
    "      \"How do you feel about your father?\",\n",
    "      \"Does your relationship with your father relate to your feelings today?\",\n",
    "      \"Do you have trouble showing affection with your family?\"]],\n",
    " \n",
    "    [r'(.*) child(.*)',\n",
    "     [\"Did you have close friends as a child?\",\n",
    "      \"What is your favorite childhood memory?\",\n",
    "      \"Do you remember any dreams or nightmares from childhood?\",\n",
    "      \"Did the other children sometimes tease you?\",\n",
    "      \"How do you think your childhood experiences relate to your feelings today?\"]],\n",
    " \n",
    "    [r'(.*)\\?',\n",
    "     [\"Why do you ask that?\",\n",
    "      \"Please consider whether you can answer your own question.\",\n",
    "      \"Perhaps the answer lies within yourself?\",\n",
    "      \"Why don't you tell me?\"]],\n",
    " \n",
    "    [r'quit',\n",
    "     [\"Thank you for talking with me.\",\n",
    "      \"Good-bye.\",\n",
    "      \"Thank you, that will be $150.  Have a good day!\"]],\n",
    " \n",
    "    [r'(.*)',\n",
    "     [\"Please tell me more.\",\n",
    "      \"Let's change focus a bit... Tell me about your family.\",\n",
    "      \"Can you elaborate on that?\",\n",
    "      \"Why do you say that {0}?\",\n",
    "      \"I see.\",\n",
    "      \"Very interesting.\",\n",
    "      \"{0}.\",\n",
    "      \"I see.  And what does that tell you?\",\n",
    "      \"How does that make you feel?\",\n",
    "      \"How do you feel when you say that?\"]]\n",
    "]\n",
    " \n",
    " \n",
    "def reflect(fragment):\n",
    "    \n",
    "    # Turn a string into a series of words\n",
    "    tokens = fragment.lower().split()\n",
    "    \n",
    "    # for each word...\n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "    \n",
    "        # see if the word is in the \"reflections\" list and if it\n",
    "        # is, replace it with its reflection (you -> me, say)\n",
    "        if token in reflections:\n",
    "            tokens[i] = reflections[token]\n",
    "            \n",
    "    return ' '.join(tokens)\n",
    " \n",
    " \n",
    "def respond(statement):\n",
    "    \n",
    "    # run through all the actions\n",
    "    for j in range(len(actions)):\n",
    "    \n",
    "        # for each one, see if it matches the statment that was typed\n",
    "        pattern = actions[j][0] \n",
    "        responses = actions[j][1]\n",
    "        found = match(pattern, statement.rstrip(\".!\"),IGNORECASE)\n",
    "        \n",
    "        if found:\n",
    "        \n",
    "            # for the first match, select a response at random and insert\n",
    "            # the text from the statement into ELIZA's response\n",
    "            response = choice(responses)\n",
    "            return response.format(*[reflect(g) for g in found.groups()])\n",
    " \n",
    " \n",
    "def eliza():\n",
    "    # a friendly welcome\n",
    "    print(\"Hello. How are you feeling today?\")\n",
    " \n",
    "    # talk forever...\n",
    "    while True:\n",
    "        \n",
    "        # collect a statement and respond, stop the conversation on 'quit'\n",
    "        statement = input(\"> \")\n",
    "        print(respond(statement))\n",
    " \n",
    "        if statement == \"quit\":\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some constructions here you haven't seen. The `def ... :` is a way to create new functions. That is, you can build your own operations that take data in, operate on it, and return in some way. \n",
    "\n",
    "The final function `eliza(),` for example, drops you into a loop (a \"while\" loop that you \"break\" out of by typing \"quit\". The only other new thing here is that the notebook has a funciton \"raw_input\" that lets your reader type things and gives you access to their musings. Play with ELIZA a little. \n",
    "\n",
    "So, what do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliza()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we turn you lose, let's examine the code a little. The `reflect()` function turns and \"I\" into a \"you\", allowing the program to turn a user's statement \"Because I love apples\" around into the question \"If you love apples, what else must be true?\" Here is `reflect()` working on single phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflect(\"I am troubled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflect(\"your analysis is wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the `respond()` function a little more closely. There are some new code constructions here. Here is `respond()` in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respond(\"I am doing fine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we take the same function but add a number of print statements to see what it's doing. The new function is called `irespond()` instead, to avoid confusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def irespond(statement):\n",
    "    \n",
    "    # run through all the actions\n",
    "    for j in range(len(actions)):\n",
    "        \n",
    "        # for each one, see if it matches the statment that was typed\n",
    "        pattern = actions[j][0] \n",
    "        responses = actions[j][1]\n",
    "        found = match(pattern, statement.rstrip(\".!\"),IGNORECASE)\n",
    "        \n",
    "        if found:\n",
    "            \n",
    "            # for the first match, select a response at random and insert\n",
    "            # the text from the statement into ELIZA's response\n",
    "            \n",
    "            print(\"Found pattern:\")\n",
    "            print(pattern)\n",
    "            print(\"--\"*5)\n",
    "            print(\"Choosing between responses:\")\n",
    "            pprint(responses)\n",
    "            \n",
    "            response = choice(responses)            \n",
    "\n",
    "            print(\"--\"*5)\n",
    "            print(\"The matched groups:\")\n",
    "            pprint([reflect(g) for g in found.groups()])\n",
    "            print(\"--\"*5)\n",
    "            \n",
    "            print(\"ELIZA's response:\")\n",
    "            print(response.format(*[reflect(g) for g in found.groups()]))\n",
    "            print(\"--\"*5)\n",
    "            \n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irespond(\"My dog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The responses have references that look like `{0}` and `{1}` and so on. Given a string with these special character strings, the method format() will substitute its first argument for `{0}`, its second for `{1}` and so on. Here we make two substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Not everything is {0} in words, only {1}\".format(\"sayable\",\"the living truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only other magic is the `*` inside the `format()` call in `irespond()` and `respond()`. What the star notation does is take a list and make it like each element is another argument for the function. So the list below has two elements, two strings, and the star make the call below just like the one above. The first element of the list is the first argument to format() and the second is the second argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Not everything is {0} in words, only {1}\".format(*[\"sayable\",\"the living truth.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this because the `match()` command returns a list of the groups identified in the regular expression -- the items marked out with parenthese. So above, the word \"dog\" is the only match and the `groups()` method returns a list with just one item. `format()` then takes that item and plops it into the response string, replacing `{0}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irespond(\"do you think my mother would approve?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irespond(\"I'm sad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn! Start by copying and adapting the ELIZA code to fix up where it seems to get stuck, conversationally. When you are ready, start on your own bot. The more rules you rewrite the better. What are you going to talk about? What are you going to ground your conversation in? Maybe we ground it in Trump commentary (unless you're exhausted -- I'll understand)? [Here](https://www.nytimes.com/2016/11/18/technology/automated-pro-trump-bots-overwhelmed-pro-clinton-messages-researchers-say.html?_r=0) is a great article on simple political chat bots and another one [here](https://www.askhillaryanddonald.com/assets/Sample_Questions.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
